{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import importlib\n",
        "from datetime import date, timedelta, datetime as dt\n",
        "\n",
        "try:\n",
        "    from snowflake.snowpark import Session, get_active_session\n",
        "    session = get_active_session()\n",
        "except ImportError:  \n",
        "    sys.path.append(os.path.abspath('/src'))\n",
        "    import src.SnowflakeConnector\n",
        "    importlib.reload(src.SnowflakeConnector)\n",
        "    from src.SnowflakeConnector import create_active_session\n",
        "    session = create_active_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dependencies\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, log_loss, recall_score, confusion_matrix\n",
        "\n",
        "\n",
        "from snowflake.snowpark.functions import col\n",
        "import snowflake.snowpark.functions as f\n",
        "from snowflake.snowpark.functions import col\n",
        "import snowflake.snowpark.functions as f\n",
        "#from snowflake.ml.registry import Registry\n",
        "\n",
        "import src.model\n",
        "import src.snapshot_split\n",
        "import importlib\n",
        "importlib.reload(src.model)\n",
        "importlib.reload(src.snapshot_split)\n",
        "\n",
        "from src.model import train_churn_model, predict_churn\n",
        "from src.snapshot_split import split_by_snapshot_dmatrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<snowflake.snowpark.dataframe.DataFrame at 0x112791370>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#dataloader\n",
        "\n",
        "df = session.table(\"analytics.analytics_inference.bimonthly_ml_features\")\n",
        "df.select(\"SNAPSHOT_WEEK\").distinct().order_by(\"SNAPSHOT_WEEK\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------\n",
            "|\"SNAPSHOT_WEEK\"  |\"COUNT\"  |\n",
            "-----------------------------\n",
            "|2025-05-12       |13582    |\n",
            "|2025-04-21       |13998    |\n",
            "|2025-05-26       |13453    |\n",
            "|2025-04-07       |14205    |\n",
            "|2025-05-19       |13473    |\n",
            "|2025-04-14       |14139    |\n",
            "|2025-04-28       |13681    |\n",
            "|2025-06-02       |13377    |\n",
            "|2025-05-05       |13682    |\n",
            "-----------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.group_by('snapshot_week').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assume you're in notebooks/\n",
        "notebook_dir = Path().resolve()\n",
        "root = notebook_dir.parent\n",
        "config_path = root / \"configs\" / \"bimonthly.yaml\"\n",
        "\n",
        "with config_path.open(\"r\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "features = config['features']\n",
        "label = config['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TRAIN TEST SPLIT\n",
        "split_date_train = dt.strptime('2025-05-05', '%Y-%m-%d').date()\n",
        "split_date_val = dt.strptime('2025-05-19', '%Y-%m-%d').date()\n",
        "dtrain, dval, dtest, df_test = split_by_snapshot_dmatrix(df, split_date_train, split_date_val, train=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TRAIN MODEL\n",
        "test_model = train_churn_model(dtrain, dval)\n",
        "eval_df = predict_churn(test_model, dtest)\n",
        "\n",
        "\n",
        "eval_df[\"ACTUAL\"] = df_test[label].values  # Add actual labels\n",
        "eval_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#EVALUATE MODEL\n",
        "\n",
        "cm = confusion_matrix(eval_df[\"ACTUAL\"], eval_df[\"PREDICTED_CLASS\"])\n",
        "\n",
        "# Create a labeled DataFrame for the confusion matrix\n",
        "cm_df = pd.DataFrame(cm, \n",
        "                     index=[\"Actual Non-Churn (0)\", \"Actual Churn (1)\"], \n",
        "                     columns=[\"Predicted Non-Churn (0)\", \"Predicted Churn (1)\"])\n",
        "\n",
        "cm_df\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#PRECISION & RECALL\n",
        "\n",
        "\n",
        "precision = precision_score(eval_df[\"ACTUAL\"], eval_df[\"PREDICTED_CLASS\"])\n",
        "recall = recall_score(eval_df[\"ACTUAL\"], eval_df[\"PREDICTED_CLASS\"])\n",
        "\n",
        "pos_neg_ratio = eval_df[\"PREDICTED_CLASS\"].sum() / (len(eval_df[\"PREDICTED_CLASS\"]))\n",
        "\n",
        "print(f\"Precision : {precision}\")\n",
        "print(f\"Recall : {recall}\")\n",
        "print(f\"Positive/All : {pos_neg_ratio}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#PLOTLY HISTOGRAM\n",
        "fig1 = px.histogram(eval_df, x='PREDICTED_PROBABILITY', nbins=10, text_auto=True)\n",
        "fig = px.histogram(eval_df[eval_df[\"PREDICTED_CLASS\"] == 1], x='PREDICTED_PROBABILITY', nbins=50, text_auto=True)\n",
        "\n",
        "st.title('Distribution of Chuned Predictions')\n",
        "st.plotly_chart(fig, use_container_width=True)\n",
        "st.title('Distribution of All Predictions')\n",
        "st.plotly_chart(fig1, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TRAIN TEST SPLIT FOR INFERENCE\n",
        "\n",
        "split_date_train = dt.strptime('2025-05-19', '%Y-%m-%d').date()\n",
        "split_date_val = dt.strptime('2025-06-02', '%Y-%m-%d').date()\n",
        "dtrain, dval, dtest, df_test = split_by_snapshot_dmatrix(df, split_date_train, split_date_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#INFERENCE MODEL TRAINING\n",
        "\n",
        "infer_model = train_churn_model(dtrain, dval)\n",
        "prob_df = predict_churn(test_model, dtest)\n",
        "\n",
        "pred_df = df_test.copy()\n",
        "pred_df[\"PREDICTED_PROBABILITY\"] = prob_df[\"PREDICTED_PROBABILITY\"].values\n",
        "pred_df[\"PREDICTED_CLASS\"] = prob_df[\"PREDICTED_CLASS\"].values\n",
        "\n",
        "pred_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#SNOWFLAKE EXPORT CREATE CAMPAIGN TABLE\n",
        "\n",
        "campaign_df = pred_df.copy()\n",
        "campaign_df = campaign_df[campaign_df[\"PREDICTED_PROBABILITY\"] > 0.7]\n",
        "inference_date =dt.strptime('2025-06-09', '%Y-%m-%d').date()\n",
        "campaign_df[\"AB_GROUP\"] = np.random.choice([\"A - Send Email\", \"B - Don't Send Email\"], size=len(campaign_df))\n",
        "\n",
        "table_name = \"PREDICTIVE.CHURN_PREDICTIONS.BIMONTHLY_\"+inference_date.strftime('%b_%d').upper() \n",
        "print(table_name)\n",
        "\n",
        "campaign_snowpark_df = session.createDataFrame(data=campaign_df)\n",
        "campaign_snowpark_df.write.save_as_table(table_name, mode=\"overwrite\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#PREDICTIONS EVALUATION\n",
        "positives = pred_df[\"PREDICTED_CLASS\"].sum()\n",
        "all = len(pred_df[\"PREDICTED_CLASS\"])\n",
        "\n",
        "pos_neg_ratio = positives / all\n",
        "\n",
        "# print(f\"Precision : {precision}\")\n",
        "print(f\"Positives : {positives}\")\n",
        "print(f\"Positive/All : {round(pos_neg_ratio,3) * 100}%\")\n",
        "print(f\"Normal Positive/All : {round(700/all,2) * 100}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#INFERENCE PREDICTIONS HISTOGRAM\n",
        "campaign_df['CHURN_PROBABILITY_PERC'] = campaign_df['PREDICTED_PROBABILITY']#*100\n",
        "#pred_df['CHURN_PROBABILITY_PERC'] = pred_df['PREDICTED_PROBABILITY']*100\n",
        "\n",
        "fig = px.histogram(campaign_df, x='CHURN_PROBABILITY_PERC', nbins=10, text_auto=True)\n",
        "st.plotly_chart(fig, use_container_width=True)\n",
        "\n",
        "\n",
        "fig1 = px.histogram(pred_df, x='PREDICTED_PROBABILITY', nbins=10, text_auto=True)\n",
        "st.plotly_chart(fig1, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#INFERENCE PREDICTIONS BINNED HISTOGRAM\n",
        "campaign_df['PREDICTED_PROBABILITY'] = pd.cut(\n",
        "    campaign_df['PREDICTED_PROBABILITY'] * 100,\n",
        "    bins=[0,10,20,30,40,50,60,70,80,90,100],\n",
        "    right=False,\n",
        "    labels=[f\"{i}-{i+10}\" for i in range(0, 100, 10)]\n",
        ")\n",
        "\n",
        "fig = px.histogram(campaign_df, x='PREDICTED_PROBABILITY', text_auto=True, category_orders={\"PREDICTED_PROBABILITY\": [f\"{i}-{i+10}\" for i in range(0, 100, 10)]})\n",
        "st.plotly_chart(fig, use_container_width=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
